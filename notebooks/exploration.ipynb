{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ClickHouse Data Exploration\n",
    "\n",
    "This notebook is for running ad-hoc, exploratory queries against our ClickHouse trade warehouse.\n",
    "\n",
    "**Setup (run in your terminal):**\n",
    "1.  Make sure you are in your project's virtual environment (or install these globally).\n",
    "2.  Install the required libraries:\n",
    "    ```bash\n",
    "    pip install jupyterlab pandas plotly clickhouse-driver\n",
    "    ```\n",
    "3.  Run the notebook: `jupyter lab`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clickhouse_driver import Client\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# --- Connection --- \n",
    "CLICKHOUSE_HOST = \"localhost\"\n",
    "CLICKHOUSE_PORT = 8123 # This is our clickhouse-01 node\n",
    "CLICKHOUSE_DB = \"default\"\n",
    "\n",
    "print(f\"Connecting to ClickHouse at {CLICKHOUSE_HOST}:{CLICKHOUSE_PORT}...\")\n",
    "try:\n",
    "    client = Client(\n",
    "        host=CLICKHOUSE_HOST,\n",
    "        port=CLICKHOUSE_PORT,\n",
    "        database=CLICKHOUSE_DB\n",
    "    )\n",
    "    # Verify connection\n",
    "    client.execute('SELECT 1')\n",
    "    print(\"Connection successful!\")\n",
    "except Exception as e:\n",
    "    print(f\"Connection failed: {e}\")\n",
    "\n",
    "# Helper function to run queries and get a DataFrame\n",
    "def query_to_df(query: str, params=None):\n",
    "    print(\"Running query...\")\n",
    "    try:\n",
    "        data, columns = client.execute(query, params=params, with_column_types=True)\n",
    "        col_names = [c[0] for c in columns]\n",
    "        df = pd.DataFrame(data, columns=col_names)\n",
    "        print(f\"Query successful. Returned {len(df)} rows.\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Query failed: {e}\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Check Ingestion\n",
    "\n",
    "Let's check if data is flowing into our tables. We query `ticks_all`, which is the `Distributed` table (our main query entry point)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT * FROM default.ticks_all\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "df_head = query_to_df(query)\n",
    "df_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT \n",
    "    symbol, \n",
    "    count() AS num_ticks\n",
    "FROM default.ticks_all\n",
    "GROUP BY symbol\n",
    "ORDER BY num_ticks DESC\n",
    "\"\"\"\n",
    "df_counts = query_to_df(query)\n",
    "df_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test Deduplication (ReplacingMergeTree)\n",
    "\n",
    "Let's check the fast (dirty) count vs. the slow (clean) count using `FINAL`. This is the same benchmark our API will run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = 'AAPL'\n",
    "\n",
    "# 1. Fast, raw count (may include duplicates)\n",
    "query_raw = \"SELECT count() FROM default.ticks_dedup WHERE symbol = %(sym)s\"\n",
    "df_raw = query_to_df(query_raw, params={'sym': symbol})\n",
    "print(f\"Raw count for {symbol}: {df_raw.iloc[0,0]}\")\n",
    "\n",
    "# 2. Slow, accurate count (forces deduplication)\n",
    "query_final = \"SELECT count() FROM default.ticks_dedup FINAL WHERE symbol = %(sym)s\"\n",
    "df_final = query_to_df(query_final, params={'sym': symbol})\n",
    "print(f\"Final count for {symbol}: {df_final.iloc[0,0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test Rollup Table (AggregatingMergeTree)\n",
    "\n",
    "Let's query our fast 1-minute rollup table. We'll grab the pre-calculated states and then use the `...Merge` functions to finalize them. This is the 'fast path' query for our API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = 'AAPL'\n",
    "limit = 10\n",
    "\n",
    "query_fast = \"\"\"\n",
    "SELECT\n",
    "    minute,\n",
    "    symbol,\n",
    "    argMinMerge(open) AS open,\n",
    "    maxMerge(high) AS high,\n",
    "    minMerge(low) AS low,\n",
    "    argMaxMerge(close) AS close,\n",
    "    sumMerge(volume) AS volume,\n",
    "    sumMerge(vwap_pv) / sumMerge(volume) AS vwap\n",
    "FROM \n",
    "    default.trades_1m_agg\n",
    "WHERE \n",
    "    symbol = %(sym)s\n",
    "GROUP BY \n",
    "    symbol, minute\n",
    "ORDER BY \n",
    "    minute DESC\n",
    "LIMIT %(lim)s\n",
    "\"\"\"\n",
    "\n",
    "df_fast = query_to_df(query_fast, params={'sym': symbol, 'lim': limit})\n",
    "df_fast"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
